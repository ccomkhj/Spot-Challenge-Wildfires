{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_Ubuntu = True\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from functools import reduce\n",
    "%matplotlib inline\n",
    "\n",
    "if is_Ubuntu:\n",
    "    H_Wildfires = pd.read_csv(r'../data/Nov_10/Historical_Wildfires.csv')\n",
    "    H_Weather = pd.read_csv(r'../data/Nov_10/HistoricalWeather.csv')\n",
    "    H_Weather_Fc = pd.read_csv(r'../data/Nov_10/HistoricalWeatherForecasts.csv')\n",
    "    LandClass = pd.read_csv(r'../data/Nov_10/LandClass.csv')\n",
    "    Vege = pd.read_csv(r'../data/Nov_10/VegetationIndex.csv')\n",
    "    Sample = pd.read_csv(r'../data/submission-example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one of two input will be necessary in Std&Var to improve computation\n",
    "I will keep Var and discard Std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_Wildfires = H_Wildfires.dropna() \n",
    "H_Wildfires=H_Wildfires.drop(columns='Std_confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reform(df, target_column, common_cols, key_cols, param_cols):\n",
    "    elements = df[target_column].unique()\n",
    "    basis = df[common_cols].drop_duplicates()\n",
    "    for elm in elements:\n",
    "        new = df[df[target_column] == elm][key_cols + param_cols]\n",
    "        rename = {}\n",
    "        for col in param_cols:\n",
    "            rename[col] = str(elm) + '_' + col\n",
    "        new = new.rename(columns=rename)\n",
    "        basis = basis.merge(new, on=key_cols)\n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Parameter'\n",
    "common_cols = ['Date', 'Region', 'count()[unit: km^2]']\n",
    "common_cols_fc = ['Date', 'Region', 'Lead time', 'count()[unit: km^2]']\n",
    "key_cols = ['Date', 'Region']\n",
    "key_cols_fc = ['Date', 'Region', 'Lead time']\n",
    "param_cols = ['min()', 'max()', 'mean()', 'variance()']\n",
    "\n",
    "H_Weather_reform = reform(H_Weather.copy(), target_column, common_cols, key_cols, param_cols)\n",
    "H_Weather_Fc_reform = reform(H_Weather_Fc.copy(), target_column, common_cols_fc, key_cols_fc, param_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "ohe.fit_transform(H_Weather_reform[['Region']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = make_column_transformer(\n",
    "(OneHotEncoder(),['Region']), remainder='passthrough')\n",
    "Weather_ohe1=column_trans.fit_transform(H_Weather_reform)\n",
    "# now Region is transformed into one-hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_wo_Region=np.delete(H_Weather_reform.columns.values,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weather_ohe=pd.DataFrame(Weather_ohe1,columns=np.concatenate((np.squeeze(np.array(ohe.categories_)),column_wo_Region)))\n",
    "Weather_ohe=Weather_ohe.reindex(columns=['Date','NSW', 'NT', 'QL', 'SA', 'TA', 'VI', 'WA','count()[unit: km^2]', 'Precipitation_min()',\n",
    "       'Precipitation_max()', 'Precipitation_mean()',\n",
    "       'Precipitation_variance()', 'RelativeHumidity_min()',\n",
    "       'RelativeHumidity_max()', 'RelativeHumidity_mean()',\n",
    "       'RelativeHumidity_variance()', 'SoilWaterContent_min()',\n",
    "       'SoilWaterContent_max()', 'SoilWaterContent_mean()',\n",
    "       'SoilWaterContent_variance()', 'SolarRadiation_min()',\n",
    "       'SolarRadiation_max()', 'SolarRadiation_mean()',\n",
    "       'SolarRadiation_variance()', 'Temperature_min()', 'Temperature_max()',\n",
    "       'Temperature_mean()', 'Temperature_variance()', 'WindSpeed_min()',\n",
    "       'WindSpeed_max()', 'WindSpeed_mean()', 'WindSpeed_variance()'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe2 = OneHotEncoder(sparse=False)\n",
    "ohe2.fit_transform(H_Wildfires[['Region']])\n",
    "column_trans2 = make_column_transformer(\n",
    "(OneHotEncoder(),['Region']), remainder='passthrough')\n",
    "H_Wildfires_ohe2=column_trans2.fit_transform(H_Wildfires.copy())\n",
    "# now Region is transformed into one-hot encoder.\n",
    "H_Wildfires_ohe2\n",
    "column_wo_Region2=np.delete(H_Wildfires.columns.values,0) # if the wrong column is deleted, change the number '0' to proper column.\n",
    "H_Wildfires_ohe=pd.DataFrame(H_Wildfires_ohe2,columns=np.concatenate((np.squeeze(np.array(ohe2.categories_)),column_wo_Region2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_Wildfires_ohe=H_Wildfires_ohe.drop(columns=['Replaced'])\n",
    "# Delete Replaced. I believe it has no impact for the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_wo_Region_LT=np.delete(H_Weather_Fc_reform.columns.values,[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccomk\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NSW</th>\n",
       "      <th>NT</th>\n",
       "      <th>QL</th>\n",
       "      <th>SA</th>\n",
       "      <th>TA</th>\n",
       "      <th>VI</th>\n",
       "      <th>WA</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>Temperature_mean()</th>\n",
       "      <th>Temperature_variance()</th>\n",
       "      <th>WindSpeed_min()</th>\n",
       "      <th>WindSpeed_max()</th>\n",
       "      <th>WindSpeed_mean()</th>\n",
       "      <th>WindSpeed_variance()</th>\n",
       "      <th>Precipitation_min()</th>\n",
       "      <th>Precipitation_max()</th>\n",
       "      <th>Precipitation_mean()</th>\n",
       "      <th>Precipitation_variance()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2808</td>\n",
       "      <td>5.67778</td>\n",
       "      <td>1.18347</td>\n",
       "      <td>7.47124</td>\n",
       "      <td>3.54142</td>\n",
       "      <td>1.09508</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676588</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>0.00412038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.207</td>\n",
       "      <td>14.5499</td>\n",
       "      <td>1.60013</td>\n",
       "      <td>9.40745</td>\n",
       "      <td>3.86108</td>\n",
       "      <td>1.02562</td>\n",
       "      <td>0</td>\n",
       "      <td>1.77573</td>\n",
       "      <td>0.0173248</td>\n",
       "      <td>0.0127447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.9354</td>\n",
       "      <td>10.5328</td>\n",
       "      <td>0.594453</td>\n",
       "      <td>10.1517</td>\n",
       "      <td>3.09188</td>\n",
       "      <td>1.25019</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00191</td>\n",
       "      <td>0.0545678</td>\n",
       "      <td>0.0276839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2577</td>\n",
       "      <td>2.69899</td>\n",
       "      <td>1.06546</td>\n",
       "      <td>7.47</td>\n",
       "      <td>3.15977</td>\n",
       "      <td>0.844959</td>\n",
       "      <td>0</td>\n",
       "      <td>4.36486</td>\n",
       "      <td>0.165038</td>\n",
       "      <td>0.150157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.78897</td>\n",
       "      <td>4.41214</td>\n",
       "      <td>2.46398</td>\n",
       "      <td>12.9962</td>\n",
       "      <td>5.26019</td>\n",
       "      <td>3.43371</td>\n",
       "      <td>0.847536</td>\n",
       "      <td>14.8248</td>\n",
       "      <td>4.98528</td>\n",
       "      <td>13.1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.7267</td>\n",
       "      <td>7.66922</td>\n",
       "      <td>0.60943</td>\n",
       "      <td>6.03806</td>\n",
       "      <td>2.70124</td>\n",
       "      <td>1.14168</td>\n",
       "      <td>0</td>\n",
       "      <td>3.75455</td>\n",
       "      <td>0.276201</td>\n",
       "      <td>0.226294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.976</td>\n",
       "      <td>9.18577</td>\n",
       "      <td>0.374749</td>\n",
       "      <td>4.46413</td>\n",
       "      <td>1.91962</td>\n",
       "      <td>0.332452</td>\n",
       "      <td>0</td>\n",
       "      <td>5.35779</td>\n",
       "      <td>0.819959</td>\n",
       "      <td>1.06442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.6578</td>\n",
       "      <td>14.7499</td>\n",
       "      <td>1.31103</td>\n",
       "      <td>9.13833</td>\n",
       "      <td>5.2456</td>\n",
       "      <td>2.62665</td>\n",
       "      <td>0</td>\n",
       "      <td>9.33236</td>\n",
       "      <td>0.590085</td>\n",
       "      <td>1.47914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.9999</td>\n",
       "      <td>14.6108</td>\n",
       "      <td>0.365395</td>\n",
       "      <td>10.5496</td>\n",
       "      <td>5.45139</td>\n",
       "      <td>2.23217</td>\n",
       "      <td>0</td>\n",
       "      <td>2.73227</td>\n",
       "      <td>0.170651</td>\n",
       "      <td>0.146198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39572</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>28.5298</td>\n",
       "      <td>32.3407</td>\n",
       "      <td>0.446725</td>\n",
       "      <td>10.2577</td>\n",
       "      <td>4.82848</td>\n",
       "      <td>2.85931</td>\n",
       "      <td>0</td>\n",
       "      <td>17.2242</td>\n",
       "      <td>0.216251</td>\n",
       "      <td>1.48644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39573 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NSW NT QL SA TA VI WA  5 10 15  ... Temperature_mean()  \\\n",
       "0       1  0  0  0  0  0  0  1  0  0  ...            10.2808   \n",
       "1       0  1  0  0  0  0  0  1  0  0  ...             18.207   \n",
       "2       0  0  1  0  0  0  0  1  0  0  ...            17.9354   \n",
       "3       0  0  0  1  0  0  0  1  0  0  ...            13.2577   \n",
       "4       0  0  0  0  1  0  0  1  0  0  ...            5.78897   \n",
       "...    .. .. .. .. .. .. .. .. .. ..  ...                ...   \n",
       "39568   0  0  0  0  0  1  0  0  1  0  ...            15.7267   \n",
       "39569   0  0  0  0  0  1  0  0  0  1  ...             16.976   \n",
       "39570   0  0  0  0  0  0  1  1  0  0  ...            26.6578   \n",
       "39571   0  0  0  0  0  0  1  0  1  0  ...            26.9999   \n",
       "39572   0  0  0  0  0  0  1  0  0  1  ...            28.5298   \n",
       "\n",
       "      Temperature_variance() WindSpeed_min() WindSpeed_max() WindSpeed_mean()  \\\n",
       "0                    5.67778         1.18347         7.47124          3.54142   \n",
       "1                    14.5499         1.60013         9.40745          3.86108   \n",
       "2                    10.5328        0.594453         10.1517          3.09188   \n",
       "3                    2.69899         1.06546            7.47          3.15977   \n",
       "4                    4.41214         2.46398         12.9962          5.26019   \n",
       "...                      ...             ...             ...              ...   \n",
       "39568                7.66922         0.60943         6.03806          2.70124   \n",
       "39569                9.18577        0.374749         4.46413          1.91962   \n",
       "39570                14.7499         1.31103         9.13833           5.2456   \n",
       "39571                14.6108        0.365395         10.5496          5.45139   \n",
       "39572                32.3407        0.446725         10.2577          4.82848   \n",
       "\n",
       "      WindSpeed_variance() Precipitation_min() Precipitation_max()  \\\n",
       "0                  1.09508                   0            0.676588   \n",
       "1                  1.02562                   0             1.77573   \n",
       "2                  1.25019                   0             2.00191   \n",
       "3                 0.844959                   0             4.36486   \n",
       "4                  3.43371            0.847536             14.8248   \n",
       "...                    ...                 ...                 ...   \n",
       "39568              1.14168                   0             3.75455   \n",
       "39569             0.332452                   0             5.35779   \n",
       "39570              2.62665                   0             9.33236   \n",
       "39571              2.23217                   0             2.73227   \n",
       "39572              2.85931                   0             17.2242   \n",
       "\n",
       "      Precipitation_mean() Precipitation_variance()  \n",
       "0                 0.015649               0.00412038  \n",
       "1                0.0173248                0.0127447  \n",
       "2                0.0545678                0.0276839  \n",
       "3                 0.165038                 0.150157  \n",
       "4                  4.98528                  13.1499  \n",
       "...                    ...                      ...  \n",
       "39568             0.276201                 0.226294  \n",
       "39569             0.819959                  1.06442  \n",
       "39570             0.590085                  1.47914  \n",
       "39571             0.170651                 0.146198  \n",
       "39572             0.216251                  1.48644  \n",
       "\n",
       "[39573 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe3 = OneHotEncoder(sparse=False)\n",
    "ohe3.fit_transform(H_Weather_Fc_reform[['Region','Lead time']])\n",
    "column_trans3 = make_column_transformer(\n",
    "(OneHotEncoder(),['Region']),(OneHotEncoder(),['Lead time']), remainder='passthrough')\n",
    "Weather_ohe3=column_trans3.fit_transform(H_Weather_Fc_reform.copy()) \n",
    "Weather_Fc_ohe = pd.DataFrame(Weather_ohe3,columns=np.concatenate((np.squeeze(np.array(np.concatenate((ohe3.categories_[0],ohe3.categories_[1])))),column_wo_Region_LT)))\n",
    "Weather_Fc_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equalize the date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_of_Vege=np.delete(Vege.columns.values,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NSW</th>\n",
       "      <th>NT</th>\n",
       "      <th>QL</th>\n",
       "      <th>SA</th>\n",
       "      <th>TA</th>\n",
       "      <th>VI</th>\n",
       "      <th>WA</th>\n",
       "      <th>Date</th>\n",
       "      <th>Vegetation_index_mean</th>\n",
       "      <th>Vegetation_index_max</th>\n",
       "      <th>Vegetation_index_min</th>\n",
       "      <th>Vegetation_index_std</th>\n",
       "      <th>Vegetation_index_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/2005</td>\n",
       "      <td>0.349202</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.204862</td>\n",
       "      <td>0.0419683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2/1/2005</td>\n",
       "      <td>0.357403</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.208673</td>\n",
       "      <td>0.0435443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3/1/2005</td>\n",
       "      <td>0.354087</td>\n",
       "      <td>0.975</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.20945</td>\n",
       "      <td>0.0438695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4/1/2005</td>\n",
       "      <td>0.347242</td>\n",
       "      <td>0.9904</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.207307</td>\n",
       "      <td>0.0429761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5/1/2005</td>\n",
       "      <td>0.345526</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.202858</td>\n",
       "      <td>0.0411514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6/1/2020</td>\n",
       "      <td>0.26376</td>\n",
       "      <td>0.9886</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.129103</td>\n",
       "      <td>0.0166675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7/1/2020</td>\n",
       "      <td>0.265321</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.148663</td>\n",
       "      <td>0.0221008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8/1/2020</td>\n",
       "      <td>0.255785</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.155347</td>\n",
       "      <td>0.0241328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9/1/2020</td>\n",
       "      <td>0.23451</td>\n",
       "      <td>0.9849</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.126898</td>\n",
       "      <td>0.0161031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10/1/2020</td>\n",
       "      <td>0.21364</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0998605</td>\n",
       "      <td>0.00997212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1330 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NSW NT QL SA TA VI WA       Date Vegetation_index_mean  \\\n",
       "0      1  0  0  0  0  0  0   1/1/2005              0.349202   \n",
       "1      1  0  0  0  0  0  0   2/1/2005              0.357403   \n",
       "2      1  0  0  0  0  0  0   3/1/2005              0.354087   \n",
       "3      1  0  0  0  0  0  0   4/1/2005              0.347242   \n",
       "4      1  0  0  0  0  0  0   5/1/2005              0.345526   \n",
       "...   .. .. .. .. .. .. ..        ...                   ...   \n",
       "1325   0  0  0  0  0  0  1   6/1/2020               0.26376   \n",
       "1326   0  0  0  0  0  0  1   7/1/2020              0.265321   \n",
       "1327   0  0  0  0  0  0  1   8/1/2020              0.255785   \n",
       "1328   0  0  0  0  0  0  1   9/1/2020               0.23451   \n",
       "1329   0  0  0  0  0  0  1  10/1/2020               0.21364   \n",
       "\n",
       "     Vegetation_index_max Vegetation_index_min Vegetation_index_std  \\\n",
       "0                  0.9972                 -0.2             0.204862   \n",
       "1                  0.9772                 -0.2             0.208673   \n",
       "2                   0.975                 -0.2              0.20945   \n",
       "3                  0.9904                 -0.2             0.207307   \n",
       "4                  0.9972                 -0.2             0.202858   \n",
       "...                   ...                  ...                  ...   \n",
       "1325               0.9886                 -0.2             0.129103   \n",
       "1326               0.9941                 -0.2             0.148663   \n",
       "1327               0.9692                 -0.2             0.155347   \n",
       "1328               0.9849                 -0.2             0.126898   \n",
       "1329               0.9782                 -0.2            0.0998605   \n",
       "\n",
       "     Vegetation_index_variance  \n",
       "0                    0.0419683  \n",
       "1                    0.0435443  \n",
       "2                    0.0438695  \n",
       "3                    0.0429761  \n",
       "4                    0.0411514  \n",
       "...                        ...  \n",
       "1325                 0.0166675  \n",
       "1326                 0.0221008  \n",
       "1327                 0.0241328  \n",
       "1328                 0.0161031  \n",
       "1329                0.00997212  \n",
       "\n",
       "[1330 rows x 13 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vege.head()\n",
    "ohe4 = OneHotEncoder(sparse=False)\n",
    "ohe4.fit_transform(Vege[['Region']])\n",
    "column_trans4 = make_column_transformer(\n",
    "(OneHotEncoder(),['Region']), remainder='passthrough')\n",
    "Vege_ohe4=column_trans4.fit_transform(Vege.copy()) \n",
    "Vege_ohe = pd.DataFrame(Vege_ohe4,columns=np.concatenate((np.squeeze(np.array(ohe4.categories_)),column_of_Vege)))\n",
    "Vege_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_Wildfires_ohe.Date=pd.to_datetime(H_Wildfires_ohe.Date)\n",
    "Weather_ohe.Date=pd.to_datetime(Weather_ohe.Date)\n",
    "Weather_Fc_ohe.Date=pd.to_datetime(Weather_Fc_ohe.Date)\n",
    "Vege_ohe.Date=pd.to_datetime(Vege_ohe.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_date = (Vege_ohe.Date[len(Vege_ohe)-1]-Vege_ohe.Date[0]).days\n",
    "len_date = len_date +31 # depends on the lenth of the last month, it should be changed.\n",
    "date = pd.date_range(start=Vege_ohe.Date[0], periods=len_date, freq='D')\n",
    "date = pd.Series(date,index=None, name='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made dates for 7 states, but it is not well combined yet. 21/Dec/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2005-01-01\n",
       "1       2005-01-02\n",
       "2       2005-01-03\n",
       "3       2005-01-04\n",
       "4       2005-01-05\n",
       "           ...    \n",
       "40476   2020-10-27\n",
       "40477   2020-10-28\n",
       "40478   2020-10-29\n",
       "40479   2020-10-30\n",
       "40480   2020-10-31\n",
       "Name: Date, Length: 40481, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = np.concatenate((date,date,date,date,date,date,date)) # 7 Regions\n",
    "# dates = date.repeat(7)\n",
    "dates = pd.Series(dates,index=None, name='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NSW</th>\n",
       "      <th>NT</th>\n",
       "      <th>QL</th>\n",
       "      <th>SA</th>\n",
       "      <th>TA</th>\n",
       "      <th>VI</th>\n",
       "      <th>WA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1330 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NSW NT QL SA TA VI WA\n",
       "0      1  0  0  0  0  0  0\n",
       "1      1  0  0  0  0  0  0\n",
       "2      1  0  0  0  0  0  0\n",
       "3      1  0  0  0  0  0  0\n",
       "4      1  0  0  0  0  0  0\n",
       "...   .. .. .. .. .. .. ..\n",
       "1325   0  0  0  0  0  0  1\n",
       "1326   0  0  0  0  0  0  1\n",
       "1327   0  0  0  0  0  0  1\n",
       "1328   0  0  0  0  0  0  1\n",
       "1329   0  0  0  0  0  0  1\n",
       "\n",
       "[1330 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vege_ohe[['NSW', 'NT', 'QL', 'SA', 'TA', 'VI', 'WA']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montly to Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame0 = [date, Vege_ohe]\n",
    "\n",
    "Vege_ohe = reduce(lambda  left,right: pd.merge(left,right,on=['Date'],\n",
    "                                            how='left'), data_frame0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>NSW</th>\n",
       "      <th>NT</th>\n",
       "      <th>QL</th>\n",
       "      <th>SA</th>\n",
       "      <th>TA</th>\n",
       "      <th>VI</th>\n",
       "      <th>WA</th>\n",
       "      <th>Vegetation_index_mean</th>\n",
       "      <th>Vegetation_index_max</th>\n",
       "      <th>Vegetation_index_min</th>\n",
       "      <th>Vegetation_index_std</th>\n",
       "      <th>Vegetation_index_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349202</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.204862</td>\n",
       "      <td>0.0419683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300478</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.152621</td>\n",
       "      <td>0.023293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.357081</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.181695</td>\n",
       "      <td>0.0330129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179208</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.0763927</td>\n",
       "      <td>0.00583585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.638585</td>\n",
       "      <td>0.992</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.16984</td>\n",
       "      <td>0.0288457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430317</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.203939</td>\n",
       "      <td>0.0415913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219956</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.097231</td>\n",
       "      <td>0.00945386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2005-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2005-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2005-01-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2005-01-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2005-01-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2005-01-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2005-01-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2005-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2005-01-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  NSW   NT   QL   SA   TA   VI   WA Vegetation_index_mean  \\\n",
       "0  2005-01-01    1    0    0    0    0    0    0              0.349202   \n",
       "1  2005-01-01    0    1    0    0    0    0    0              0.300478   \n",
       "2  2005-01-01    0    0    1    0    0    0    0              0.357081   \n",
       "3  2005-01-01    0    0    0    1    0    0    0              0.179208   \n",
       "4  2005-01-01    0    0    0    0    1    0    0              0.638585   \n",
       "5  2005-01-01    0    0    0    0    0    1    0              0.430317   \n",
       "6  2005-01-01    0    0    0    0    0    0    1              0.219956   \n",
       "7  2005-01-02  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "8  2005-01-03  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "9  2005-01-04  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "10 2005-01-05  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "11 2005-01-06  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "12 2005-01-07  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "13 2005-01-08  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "14 2005-01-09  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "15 2005-01-10  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "16 2005-01-11  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "17 2005-01-12  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "18 2005-01-13  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "19 2005-01-14  NaN  NaN  NaN  NaN  NaN  NaN  NaN                   NaN   \n",
       "\n",
       "   Vegetation_index_max Vegetation_index_min Vegetation_index_std  \\\n",
       "0                0.9972                 -0.2             0.204862   \n",
       "1                0.9986                 -0.2             0.152621   \n",
       "2                0.9995                 -0.2             0.181695   \n",
       "3                0.9634                 -0.2            0.0763927   \n",
       "4                 0.992                 -0.2              0.16984   \n",
       "5                0.9912                 -0.2             0.203939   \n",
       "6                0.9968                 -0.2             0.097231   \n",
       "7                   NaN                  NaN                  NaN   \n",
       "8                   NaN                  NaN                  NaN   \n",
       "9                   NaN                  NaN                  NaN   \n",
       "10                  NaN                  NaN                  NaN   \n",
       "11                  NaN                  NaN                  NaN   \n",
       "12                  NaN                  NaN                  NaN   \n",
       "13                  NaN                  NaN                  NaN   \n",
       "14                  NaN                  NaN                  NaN   \n",
       "15                  NaN                  NaN                  NaN   \n",
       "16                  NaN                  NaN                  NaN   \n",
       "17                  NaN                  NaN                  NaN   \n",
       "18                  NaN                  NaN                  NaN   \n",
       "19                  NaN                  NaN                  NaN   \n",
       "\n",
       "   Vegetation_index_variance  \n",
       "0                  0.0419683  \n",
       "1                   0.023293  \n",
       "2                  0.0330129  \n",
       "3                 0.00583585  \n",
       "4                  0.0288457  \n",
       "5                  0.0415913  \n",
       "6                 0.00945386  \n",
       "7                        NaN  \n",
       "8                        NaN  \n",
       "9                        NaN  \n",
       "10                       NaN  \n",
       "11                       NaN  \n",
       "12                       NaN  \n",
       "13                       NaN  \n",
       "14                       NaN  \n",
       "15                       NaN  \n",
       "16                       NaN  \n",
       "17                       NaN  \n",
       "18                       NaN  \n",
       "19                       NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Vege_ohe.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging four dataframe   \n",
    "One easy way to fill the missing value : applying 'fillna()' or interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = [H_Wildfires_ohe, Weather_ohe, Weather_Fc_ohe]\n",
    "# NaN = 0 version\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['Date','NSW', 'NT', 'QL', 'SA', 'TA', 'VI', 'WA'],\n",
    "                                            how='outer'), data_frames).fillna(0)\n",
    "\n",
    "# data_frames2 = [df_merged, Vege_ohe]\n",
    "# # NaN is interpolated version\n",
    "# Input = reduce(lambda  left,right: pd.merge(left,right,on=['Date','NSW', 'NT', 'QL', 'SA', 'TA', 'VI', 'WA'],\n",
    "#                                             how='left'), data_frames2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NSW</th>\n",
       "      <th>NT</th>\n",
       "      <th>QL</th>\n",
       "      <th>SA</th>\n",
       "      <th>TA</th>\n",
       "      <th>VI</th>\n",
       "      <th>WA</th>\n",
       "      <th>Date</th>\n",
       "      <th>Estimated_fire_area</th>\n",
       "      <th>Mean_estimated_fire_brightness</th>\n",
       "      <th>...</th>\n",
       "      <th>WindSpeed_variance()_y</th>\n",
       "      <th>Precipitation_min()_y</th>\n",
       "      <th>Precipitation_max()_y</th>\n",
       "      <th>Precipitation_mean()_y</th>\n",
       "      <th>Precipitation_variance()_y</th>\n",
       "      <th>Vegetation_index_mean</th>\n",
       "      <th>Vegetation_index_max</th>\n",
       "      <th>Vegetation_index_min</th>\n",
       "      <th>Vegetation_index_std</th>\n",
       "      <th>Vegetation_index_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>8.68000</td>\n",
       "      <td>312.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>16.61125</td>\n",
       "      <td>322.475000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>5.52000</td>\n",
       "      <td>325.266667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-01-07</td>\n",
       "      <td>6.26400</td>\n",
       "      <td>313.870000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-01-08</td>\n",
       "      <td>5.40000</td>\n",
       "      <td>337.383333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66421</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.339756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.484133</td>\n",
       "      <td>0.708612</td>\n",
       "      <td>0.639895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.553463</td>\n",
       "      <td>0.084519</td>\n",
       "      <td>2.884705</td>\n",
       "      <td>0.859000</td>\n",
       "      <td>0.651382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66423</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.764997</td>\n",
       "      <td>0.613490</td>\n",
       "      <td>19.982969</td>\n",
       "      <td>6.989541</td>\n",
       "      <td>24.894519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66424</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.359123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.854244</td>\n",
       "      <td>0.324972</td>\n",
       "      <td>0.391030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66425</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.775353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.645476</td>\n",
       "      <td>0.194434</td>\n",
       "      <td>0.048402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66426 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      NSW NT QL SA TA VI WA       Date  Estimated_fire_area  \\\n",
       "0       1  0  0  0  0  0  0 2005-01-04              8.68000   \n",
       "1       1  0  0  0  0  0  0 2005-01-05             16.61125   \n",
       "2       1  0  0  0  0  0  0 2005-01-06              5.52000   \n",
       "3       1  0  0  0  0  0  0 2005-01-07              6.26400   \n",
       "4       1  0  0  0  0  0  0 2005-01-08              5.40000   \n",
       "...    .. .. .. .. .. .. ..        ...                  ...   \n",
       "66421   0  0  0  0  1  0  0 2019-07-12              0.00000   \n",
       "66422   0  0  0  0  1  0  0 2019-07-12              0.00000   \n",
       "66423   0  0  0  0  0  1  0 2019-07-12              0.00000   \n",
       "66424   0  0  0  0  0  1  0 2019-07-12              0.00000   \n",
       "66425   0  0  0  0  0  1  0 2019-07-12              0.00000   \n",
       "\n",
       "       Mean_estimated_fire_brightness  ...  WindSpeed_variance()_y  \\\n",
       "0                          312.266667  ...                0.000000   \n",
       "1                          322.475000  ...                0.000000   \n",
       "2                          325.266667  ...                0.000000   \n",
       "3                          313.870000  ...                0.000000   \n",
       "4                          337.383333  ...                0.000000   \n",
       "...                               ...  ...                     ...   \n",
       "66421                        0.000000  ...                3.339756   \n",
       "66422                        0.000000  ...                1.553463   \n",
       "66423                        0.000000  ...                2.764997   \n",
       "66424                        0.000000  ...                3.359123   \n",
       "66425                        0.000000  ...                2.775353   \n",
       "\n",
       "       Precipitation_min()_y  Precipitation_max()_y  Precipitation_mean()_y  \\\n",
       "0                   0.000000               0.000000                0.000000   \n",
       "1                   0.000000               0.000000                0.000000   \n",
       "2                   0.000000               0.000000                0.000000   \n",
       "3                   0.000000               0.000000                0.000000   \n",
       "4                   0.000000               0.000000                0.000000   \n",
       "...                      ...                    ...                     ...   \n",
       "66421               0.000000               2.484133                0.708612   \n",
       "66422               0.084519               2.884705                0.859000   \n",
       "66423               0.613490              19.982969                6.989541   \n",
       "66424               0.000000               2.854244                0.324972   \n",
       "66425               0.000000               1.645476                0.194434   \n",
       "\n",
       "       Precipitation_variance()_y  Vegetation_index_mean  \\\n",
       "0                        0.000000                    NaN   \n",
       "1                        0.000000                    NaN   \n",
       "2                        0.000000                    NaN   \n",
       "3                        0.000000                    NaN   \n",
       "4                        0.000000                    NaN   \n",
       "...                           ...                    ...   \n",
       "66421                    0.639895                    NaN   \n",
       "66422                    0.651382                    NaN   \n",
       "66423                   24.894519                    NaN   \n",
       "66424                    0.391030                    NaN   \n",
       "66425                    0.048402                    NaN   \n",
       "\n",
       "       Vegetation_index_max  Vegetation_index_min  Vegetation_index_std  \\\n",
       "0                       NaN                   NaN                   NaN   \n",
       "1                       NaN                   NaN                   NaN   \n",
       "2                       NaN                   NaN                   NaN   \n",
       "3                       NaN                   NaN                   NaN   \n",
       "4                       NaN                   NaN                   NaN   \n",
       "...                     ...                   ...                   ...   \n",
       "66421                   NaN                   NaN                   NaN   \n",
       "66422                   NaN                   NaN                   NaN   \n",
       "66423                   NaN                   NaN                   NaN   \n",
       "66424                   NaN                   NaN                   NaN   \n",
       "66425                   NaN                   NaN                   NaN   \n",
       "\n",
       "       Vegetation_index_variance  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  \n",
       "...                          ...  \n",
       "66421                        NaN  \n",
       "66422                        NaN  \n",
       "66423                        NaN  \n",
       "66424                        NaN  \n",
       "66425                        NaN  \n",
       "\n",
       "[66426 rows x 68 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = pd.merge(H_Wildfires_ohe, Weather_ohe, how='inner', on=['Date','NSW', 'NT', 'QL', 'SA', 'TA', 'VI', 'WA'])\n",
    "Input = Input.sort_values(['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 Dec. Use only one region's data, to see the performance of different models. Choose region WA because it has the most data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Input[Input.WA == 1]\n",
    "drop_columns = ['Date']\n",
    "for col in df.columns: # avoid deviding by zero during normalization\n",
    "    if df[col].max()==df[col].min():\n",
    "        drop_columns.append(col)\n",
    "df = df.drop(columns = drop_columns)\n",
    "df=(df-df.min())/(df.max()-df.min())  # Normalization\n",
    "\n",
    "num_features = df.shape[1]\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple model (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'A': np.linspace(0.0, 100.0, num=301), 'B': np.linspace(0.0, 100, num=301), 'Estimated_fire_area': np.linspace(0, 200, num=301)})\n",
    "# num_features = df.shape[1]\n",
    "\n",
    "# n = len(df)\n",
    "# train_df = df[0:int(n*0.7)]\n",
    "# val_df = df[int(n*0.7):int(n*0.9)]\n",
    "# test_df = df[int(n*0.9):]\n",
    "\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Indexex and offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "               label_columns=['Estimated_fire_area']):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(self, model=None, plot_col='Estimated_fire_area', max_subplots=3):\n",
    "  inputs, labels = self.example\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  plot_col_index = self.column_indices[plot_col]\n",
    "  max_n = min(max_subplots, len(inputs))\n",
    "  for n in range(max_n):\n",
    "    plt.subplot(3, 1, n+1)\n",
    "    plt.ylabel(f'{plot_col} [normed]')\n",
    "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "             label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "    if self.label_columns:\n",
    "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "    else:\n",
    "      label_col_index = plot_col_index\n",
    "\n",
    "    if label_col_index is None:\n",
    "      continue\n",
    "\n",
    "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "    if model is not None:\n",
    "      predictions = model(inputs)\n",
    "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                  marker='X', edgecolors='k', label='Predictions',\n",
    "                  c='#ff7f0e', s=64)\n",
    "\n",
    "    if n == 0:\n",
    "      plt.legend()\n",
    "\n",
    "  plt.xlabel('Day')\n",
    "\n",
    "WindowGenerator.plot = plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create tf.data.Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(self, data):\n",
    "    \n",
    "  data = np.array(data, dtype=np.float32)    \n",
    "#   data1 = np.array(data.drop(columns='Estimated_fire_area'), dtype=np.float32)\n",
    "#   targets = np.array(data['Estimated_fire_area'], dtype=np.float32)\n",
    "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,  # If this is 7, Could it work as daily moving???\n",
    "      shuffle=False,\n",
    "      batch_size=16,)\n",
    "\n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    print('No example batch was found, so get one from the `.train` dataset')\n",
    "    result = next(iter(self.train))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_EPOCHS = 200\n",
    "\n",
    "def compile_and_fit(model, window, patience=10, epochs=100):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "    \n",
    "    history = model.fit(window.train, epochs=epochs,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "    return history\n",
    "\n",
    "val_performance = {}\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WA region data\n",
    "OUT_STEPS = 28\n",
    "multi_window = WindowGenerator(input_width=31,\n",
    "                               label_width=OUT_STEPS,\n",
    "                               shift=OUT_STEPS,label_columns=['Estimated_fire_area'],\n",
    "                              train_df=train_df, val_df=val_df, test_df=test_df,)\n",
    "\n",
    "multi_window.plot()\n",
    "multi_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each element is an (inputs, label) pair\n",
    "multi_window.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history_object, plot_columns = ['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error']):\n",
    "    fig_num = len(plot_columns)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for n in range(fig_num):\n",
    "        plt.subplot(fig_num, 1, n+1)\n",
    "        plt.ylabel(plot_columns[n])\n",
    "        plt.plot(history_object.history[plot_columns[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units]\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.Dense(20),\n",
    "    tf.keras.layers.GRU(50, return_sequences=True, return_state=False),\n",
    "    tf.keras.layers.GRU(50), \n",
    "    # Shape => [batch, out_steps*features]\n",
    "    tf.keras.layers.Dense(OUT_STEPS,\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS,1])\n",
    "                          )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = compile_and_fit(multi_lstm_model, multi_window, epochs=300)\n",
    "plot_history(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lstm_model.predict(multi_window.val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I change to GRU instead of LSTM, it works better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance['M_LSTM'] = multi_lstm_model.evaluate(multi_window.val)\n",
    "performance['M_LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_window.plot(multi_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_WIDTH = 28\n",
    "multi_conv_model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :]),\n",
    "    # Shape => [batch, 1, conv_units]\n",
    "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(CONV_WIDTH)),\n",
    "    # Shape => [batch, 1,  out_steps*features]\n",
    "    tf.keras.layers.Dense(OUT_STEPS*1,\n",
    "                          kernel_initializer=tf.initializers.zeros),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, 1])\n",
    "])\n",
    "\n",
    "history = compile_and_fit(multi_conv_model, multi_window, epochs=100)\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_conv_model.predict(multi_window.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance['Conv'] = multi_conv_model.evaluate(multi_window.val)\n",
    "performance['Conv'] = multi_conv_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_window.plot(multi_conv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Autoregressive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedBack(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "        # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(num_features)\n",
    "    def warmup(self, inputs):\n",
    "        # inputs.shape => (batch, time, features)\n",
    "        # x.shape => (batch, lstm_units)\n",
    "        x, *state = self.lstm_rnn(inputs)\n",
    "\n",
    "        # predictions.shape => (batch, features)\n",
    "        prediction = self.dense(x)\n",
    "        return prediction, state\n",
    "    def call(self, inputs, training=None):\n",
    "        # Use a TensorArray to capture dynamically unrolled outputs.\n",
    "        predictions = []\n",
    "        # Initialize the lstm state\n",
    "        prediction, state = self.warmup(inputs)\n",
    "\n",
    "        # Insert the first prediction\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        # Run the rest of the prediction steps\n",
    "        for n in range(1, self.out_steps):\n",
    "            # Use the last prediction as input.\n",
    "            x = prediction\n",
    "            # Execute one lstm step.\n",
    "            x, state = self.lstm_cell(x, states=state,\n",
    "                                      training=training)\n",
    "            # Convert the lstm output to a prediction.\n",
    "            prediction = self.dense(x)\n",
    "            # Add the prediction to the output\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        # predictions.shape => (time, batch, features)\n",
    "        predictions = tf.stack(predictions)\n",
    "        # predictions.shape => (batch, time, features)\n",
    "        predictions = tf.transpose(predictions, [1, 0, 2])\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_model = FeedBack(units=32, out_steps=OUT_STEPS)\n",
    "prediction, state = feedback_model.warmup(multi_window.example[0])\n",
    "print('prediction.shape', prediction.shape)\n",
    "print('Output shape (batch, time, features): ', feedback_model(multi_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ar = compile_and_fit(feedback_model, multi_window, epochs=200)\n",
    "plot_history(history_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance['AR LSTM'] = feedback_model.evaluate(multi_window.val)\n",
    "performance['AR LSTM'] = feedback_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_window.plot(feedback_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref:\n",
    "# https://towardsdatascience.com/using-lstm-autoencoders-on-multidimensional-time-series-data-f5a7a51b29a1\n",
    "# https://machinelearningmastery.com/lstm-autoencoders/\n",
    "window_length = 31\n",
    "output_length = 28\n",
    "feats = 55\n",
    "autoencoder_model = tf.keras.Sequential([\n",
    "#     keras.layers.LSTM(64, kernel_initializer='he_uniform', batch_input_shape=(None, window_length, feats), return_sequences=True, name='encoder_1'),\n",
    "    keras.layers.LSTM(64, kernel_initializer='he_uniform', batch_input_shape=(None, window_length, feats), return_sequences=True, name='encoder_1'),\n",
    "    keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='encoder_2'),\n",
    "    keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=False, name='encoder_3'), \n",
    "    keras.layers.RepeatVector(output_length, name='encoder_decoder_bridge'),\n",
    "    keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=True, name='decoder_1'),\n",
    "    keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='decoder_2'),\n",
    "    keras.layers.LSTM(64, kernel_initializer='he_uniform', return_sequences=True, name='decoder_3'),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(feats))\n",
    "                          ])\n",
    "# autoencoder_model = keras.Sequential()\n",
    "# autoencoder_model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', batch_input_shape=(None, window_length, feats), return_sequences=True, name='encoder_1'))\n",
    "# autoencoder_model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='encoder_2'))\n",
    "# autoencoder_model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=False, name='encoder_3'))\n",
    "# autoencoder_model.add(keras.layers.RepeatVector(window_length, name='encoder_decoder_bridge'))\n",
    "# autoencoder_model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=True, name='decoder_1'))\n",
    "# autoencoder_model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='decoder_2'))\n",
    "# autoencoder_model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', return_sequences=True, name='decoder_3'))\n",
    "# autoencoder_model.add(keras.layers.TimeDistributed(keras.layers.Dense(feats)))\n",
    "# autoencoder_model.compile(loss=\"mse\",optimizer='adam')\n",
    "# autoencoder_model.build()\n",
    "# print(autoencoder_model.summary())\n",
    "\n",
    "# autoencoder_model.fit(x=X, y=Y, validation_data=(XX, YY), epochs=100, batch_size=batch_size, shuffle=True, callbacks=[early_stop])\n",
    "history_encode = compile_and_fit(autoencoder_model, multi_window, epochs=100)\n",
    "plot_history(history_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance['Encoder'] = autoencoder_model.evaluate(multi_window.val)\n",
    "performance['Encoder'] = autoencoder_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_window.plot(autoencoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(performance))\n",
    "width = 0.3\n",
    "\n",
    "metric_name = 'mean_absolute_error'\n",
    "metric_index = multi_lstm_model.metrics_names.index('mean_absolute_error')\n",
    "val_mae = [v[metric_index] for v in val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in performance.values()]\n",
    "\n",
    "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
    "plt.xticks(ticks=x, labels=performance.keys(),\n",
    "           rotation=45)\n",
    "plt.ylabel('MAE (average over all outputs)')\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_inputs, example_labels in multi_window.train.take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
